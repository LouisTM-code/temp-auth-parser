import streamlit as st
import pandas as pd
import logging
from io import BytesIO
from typing import List, Dict, Any, Optional
from catalog_parser import CatalogParser
from page_parser import PageParser
from config_reader import ConfigReader
from auth import CNC1Auth

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–≥–≥–µ—Ä–∞
logger = logging.getLogger(__name__)

class StreamlitLogger:
    """–ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ª–æ–≥–æ–≤ –≤ Streamlit –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å"""
    def __init__(self):
        self.log_container = st.empty()
        self.logs: List[str] = []
        
    def log(self, message: str, level: str = "info"):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –ª–æ–≥"""
        log_entry = f"[{level.upper()}] {message}"
        self.logs.append(log_entry)
        
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 —Å–æ–æ–±—â–µ–Ω–∏–π
        display_log = "\n".join(self.logs[-20:])
        self.log_container.text_area("–ñ—É—Ä–Ω–∞–ª –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:", 
                                    value=display_log, 
                                    height=200,
                                    disabled=True)
        
    def clear(self):
        """–û—á–∏—Å—Ç–∫–∞ –ª–æ–≥–æ–≤"""
        self.logs = []
        self.log_container.empty()

class InputManager:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–≤–æ–¥–æ–º –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π URL"""
    @staticmethod
    def get_urls(link_type: str) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å–ø–∏—Å–∫–∞ URL"""
        url_input = st.text_area(
            "–í–≤–µ–¥–∏—Ç–µ URL (–∫–∞–∂–¥—ã–π —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏ –∏–ª–∏ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é):",
            height=150,
            placeholder="https://example.com/page1\nhttps://example.com/page2"
        )
        
        if not url_input:
            return []
            
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ URL –ø–æ –ø–µ—Ä–µ–Ω–æ—Å–∞–º –∏ –∑–∞–ø—è—Ç—ã–º
        urls = []
        for line in url_input.splitlines():
            if "," in line:
                urls.extend([u.strip() for u in line.split(",") if u.strip()])
            else:
                if line.strip():
                    urls.append(line.strip())
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è URL
        valid_urls = []
        for url in urls:
            if url.startswith(("http://", "https://")):
                # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä SHOWALL_1=1 –¥–ª—è –∫–∞—Ç–∞–ª–æ–≥–æ–≤
                if link_type == "–ö–∞—Ç–∞–ª–æ–≥":
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ URL
                    if '?' in url:
                        # –ï—Å–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —É–∂–µ –µ—Å—Ç—å, –¥–æ–±–∞–≤–ª—è–µ–º —Å &
                        if 'SHOWALL_1=1' not in url:
                            url += '&SHOWALL_1=1'
                    else:
                        # –ï—Å–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–µ—Ç, –¥–æ–±–∞–≤–ª—è–µ–º —Å ?
                        url += '?SHOWALL_1=1'
                valid_urls.append(url)
            else:
                st.warning(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL: {url} (–¥–æ–ª–∂–µ–Ω –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å http:// –∏–ª–∏ https://)")
        
        return valid_urls

class ResultDispatcher:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    @staticmethod
    def preview_data(df: pd.DataFrame):
        """–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—á–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ"""
        if not df.empty:
            st.subheader("–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö")
            st.dataframe(df.head(50))
            st.info(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}")
        else:
            st.warning("–î–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")

class ResultExporter:
    """–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã"""
    @staticmethod
    def to_csv(df: pd.DataFrame) -> bytes:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DataFrame –≤ CSV"""
        return df.to_csv(index=True).encode('utf-8')
    
    @staticmethod
    def to_excel(df: pd.DataFrame) -> bytes:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DataFrame –≤ Excel"""
        output = BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            df.to_excel(writer, sheet_name='Products')
        return output.getvalue()

class WebInterface:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
    def __init__(self):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Å—Å–∏–∏
        if 'df' not in st.session_state:
            st.session_state.df = pd.DataFrame()
        if 'parsing' not in st.session_state:
            st.session_state.parsing = False
        if 'stop_requested' not in st.session_state:
            st.session_state.stop_requested = False
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        self.config = ConfigReader()
        self.auth = self._init_auth()
        self.logger = StreamlitLogger()
        
    def _init_auth(self) -> Optional[CNC1Auth]:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        try:
            credentials = self.config.get_auth_credentials()
            if credentials['email'] and credentials['password']:
                auth = CNC1Auth(credentials['email'], credentials['password'])
                if auth.login():
                    return auth
                else:
                    st.error("–û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—á–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.")
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏: {str(e)}")
        return None

    def _parse_catalog(self, urls: List[str]) -> List[str]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∫–∞—Ç–∞–ª–æ–≥–∞ –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ç–æ–≤–∞—Ä—ã"""
        parser = CatalogParser(
            urls=urls,
            link_selector=self.config.get_link_selector(),
            auth=self.auth
        )
        
        catalog_result = parser.parse()
        product_urls = []
        
        for category, urls in catalog_result.items():
            self.logger.log(f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è '{category}': {len(urls)} —Ç–æ–≤–∞—Ä–æ–≤")
            product_urls.extend(urls)
        
        return product_urls

    def _parse_products(self, urls: List[str]) -> pd.DataFrame:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü —Ç–æ–≤–∞—Ä–æ–≤"""
        parser = PageParser(
            urls=urls,
            selectors=self.config.get_selectors(),
            auth=self.auth
        )
        
        return parser.parse()
    
    def _normalize_article(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∞—Ä—Ç–∏–∫—É–ª–∞: –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–µ—Ñ–∏–∫—Å–∞ 123-"""
        if not df.empty and "–ê—Ä—Ç–∏–∫—É–ª" in df.columns:
            # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
            normalized_df = df.copy()
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ –∫ –Ω–µ–ø—É—Å—Ç—ã–º –∑–Ω–∞—á–µ–Ω–∏—è–º
            normalized_df["–ê—Ä—Ç–∏–∫—É–ª"] = normalized_df["–ê—Ä—Ç–∏–∫—É–ª"].apply(
                lambda x: f"123-{x}" if x and not pd.isna(x) else x
            )
            return normalized_df
        return df

    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
        st.title("üõ†Ô∏è –ü–∞—Ä—Å–µ—Ä CNC1")
        st.markdown("---")
        
        # –ü–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—å —Ç–∏–ø–∞ —Å—Å—ã–ª–æ–∫
        link_type = st.radio(
            "–¢–∏–ø –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã—Ö —Å—Å—ã–ª–æ–∫:",
            ["–ö–∞—Ä—Ç–æ—á–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤", "–ö–∞—Ç–∞–ª–æ–≥"],
            index=0,
            horizontal=True
        )
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ URL
        input_urls = InputManager.get_urls(link_type)
        
        col1, col2 = st.columns(2)
        with col1:
            start_btn = st.button(
                "üöÄ –ù–∞—á–∞—Ç—å –ø–∞—Ä—Å–∏–Ω–≥", 
                disabled=st.session_state.parsing or not input_urls
            )
        with col2:
            stop_btn = st.button(
                "‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å", 
                disabled=not st.session_state.parsing
            )
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–Ω–æ–ø–æ–∫
        if start_btn and input_urls:
            st.session_state.parsing = True
            st.session_state.stop_requested = False
            self.logger.clear()
            
            try:
                # –í—ã–±–æ—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞
                if link_type == "–ö–∞—Ç–∞–ª–æ–≥":
                    self.logger.log("–ù–∞—á–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥ –∫–∞—Ç–∞–ª–æ–≥–∞...")
                    product_urls = self._parse_catalog(input_urls)
                    
                    if not product_urls:
                        st.error("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ç–æ–≤–∞—Ä—ã –≤ –∫–∞—Ç–∞–ª–æ–≥–µ")
                        st.session_state.parsing = False
                        return
                        
                    self.logger.log(f"–í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞: {len(product_urls)}")
                    st.session_state.df = self._parse_products(product_urls)
                else:
                    self.logger.log("–ù–∞—á–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥ –∫–∞—Ä—Ç–æ—á–µ–∫ —Ç–æ–≤–∞—Ä–æ–≤...")
                    st.session_state.df = self._parse_products(input_urls)
                
                self.logger.log("–ü–∞—Ä—Å–∏–Ω–≥ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!", "success")
                
            except Exception as e:
                self.logger.log(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}", "error")
                st.error("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –ø–∞—Ä—Å–∏–Ω–≥–∞")
                
            finally:
                st.session_state.parsing = False
        
        if stop_btn:
            st.session_state.stop_requested = True
            st.session_state.parsing = False
            self.logger.log("–ü–∞—Ä—Å–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º", "warning")
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–µ—Ä–µ–¥ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
        display_df = self._normalize_article(st.session_state.df)

        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        ResultDispatcher.preview_data(display_df)
        
        # –ö–Ω–æ–ø–∫–∏ —ç–∫—Å–ø–æ—Ä—Ç–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
        if not st.session_state.df.empty:
            st.markdown("### üì• –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            
            col1, col2 = st.columns(2)
            with col1:
                # –≠–∫—Å–ø–æ—Ä—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                normalized_df = self._normalize_article(st.session_state.df)
                csv_data = ResultExporter.to_csv(normalized_df)
                st.download_button(
                    "üíæ –°–∫–∞—á–∞—Ç—å CSV",
                    data=csv_data,
                    file_name='products.csv',
                    mime='text/csv',
                )
            
            with col2:
                # –≠–∫—Å–ø–æ—Ä—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                normalized_df = self._normalize_article(st.session_state.df)
                excel_data = ResultExporter.to_excel(normalized_df)
                st.download_button(
                    "üíæ –°–∫–∞—á–∞—Ç—å XLSX",
                    data=excel_data,
                    file_name='products.xlsx',
                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                )

if __name__ == "__main__":
    web_ui = WebInterface()
    web_ui.run()