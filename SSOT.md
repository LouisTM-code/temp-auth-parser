# Source Of Truth
> –≠—Ç–æ Source Of Truth –∫–æ–¥–æ–≤–æ–π –±–∞–∑—ã –ø—Ä–æ–≥—Ä–∞–º–º—ã –∫–∞–∂–¥–æ–≥–æ –º–æ–¥—É–ª—è.

## `auth.py`
* **–û–ø–∏—Å–∞–Ω–∏–µ**: –ö–ª–∞—Å—Å `CNC1Auth` –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –Ω–∞ —Å–∞–π—Ç–µ. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç requests.Session –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è (cookie). –ù–µ–æ–±—Ö–æ–¥–∏–º –¥–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.
* **–ê–∫—Ç—É–∞–ª—å–Ω—ã–π –∫–æ–¥ `auth.py`**:
```python
import requests
from typing import Optional

class CNC1Auth:
    LOGIN_URL = "https://cnc1.ru/auth/?login=yes"
    HEADERS = {
        "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
        "X-Requested-With": "XMLHttpRequest",
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36",
        "Referer": "https://cnc1.ru/?login=yes",
    }

    def __init__(self, username: str, password: str):
        self.username = username
        self.password = password
        self.session = requests.Session()
        self._is_authenticated = False

    def login(self) -> bool:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –ø—Ä–∏ —É—Å–ø–µ—Ö–µ.
        """
        payload = {
            "backurl": "/?login=yes",
            "AUTH_FORM": "Y",
            "TYPE": "AUTH",
            "POPUP_AUTH": "Y",
            "AUTH_TYPE": "login",
            "USER_LOGIN": self.username,
            "USER_PASSWORD": self.password,
            "Login": "Y"
        }

        response = self.session.post(self.LOGIN_URL, headers=self.HEADERS, data=payload)

        if response.status_code == 200 and "–û—à–∏–±–∫–∞" not in response.text:
            self._is_authenticated = True
            return True
        return False

    def get(self, url: str, **kwargs) -> Optional[requests.Response]:
        """
        GET-–∑–∞–ø—Ä–æ—Å —Å –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–π —Å–µ—Å—Å–∏–µ–π. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç None, –µ—Å–ª–∏ –Ω–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω.
        """
        if not self._is_authenticated:
            return None
        headers = kwargs.pop("headers", {})
        headers.setdefault("User-Agent", self.HEADERS["User-Agent"])
        return self.session.get(url, headers=headers, **kwargs)

    def is_authenticated(self) -> bool:
        return self._is_authenticated

    def get_session(self) -> Optional[requests.Session]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–µ—Å—Å–∏—é, –µ—Å–ª–∏ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ.
        """
        return self.session if self._is_authenticated else None
```

---
## `page_pareser.py`
* **–û–ø–∏—Å–∞–Ω–∏–µ**:  –ö–ª–∞—Å—Å `PageParser`, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –ø–∞—Ä—Å–∏—Ç—å —É–∫–∞–∑–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º CSS-—Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º –∏ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –≤–∏–¥–µ DataFrame.
* **–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç**: DataFrame, –≥–¥–µ —Å—Ç—Ä–æ–∫–∞ - —Å—ã–ª–∫–∞, —Å—Ç–æ–ª–±–µ—Ü - –ù–∞–∑–≤–∞–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è, —è—á–µ–π–∫–∞ - —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ.
* **–ê–∫—Ç—É–∞–ª—å–Ω—ã–π –∫–æ–¥ `page_parser.py**:
```python
import requests
import pandas as pd
from bs4 import BeautifulSoup
from typing import Dict, List, Union, Optional, Any
from auth import CNC1Auth  # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∫–ª–∞—Å—Å –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏

class PageParser:
    def __init__(
        self,
        urls: Union[str, List[str]],
        selectors: Dict[str, str],
        auth: Optional[CNC1Auth] = None  # –£–∫–∞–∑—ã–≤–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–∏–ø –≤–º–µ—Å—Ç–æ object
    ) -> None:
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞.
        
        :param urls: URL –∏–ª–∏ —Å–ø–∏—Å–æ–∫ URL –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
        :param selectors: –°–ª–æ–≤–∞—Ä—å {–Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞: CSS-—Å–µ–ª–µ–∫—Ç–æ—Ä}
        :param auth: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –æ–±—ä–µ–∫—Ç –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ CNC1Auth
        """
        self.urls = [urls] if isinstance(urls, str) else urls
        self.selectors = selectors
        self.auth = auth
        self.data: List[Dict[str, Optional[str]]] = []  # –Ø–≤–Ω–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ —Ç–∏–ø–∞ –¥–∞–Ω–Ω—ã—Ö

    def parse(self) -> pd.DataFrame:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        for url in self.urls:
            response = self._fetch_page(url)
            if response is None or not response.ok:
                self._add_empty_row(url)
                continue
                
            self._parse_page(url, response)
            
        return self._build_dataframe()

    def _fetch_page(self, url: str) -> Optional[requests.Response]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        try:
            if self.auth and self.auth.is_authenticated():
                return self.auth.get(url)  # –¢–µ–ø–µ—Ä—å mypy –∑–Ω–∞–µ—Ç, —á—Ç–æ auth –∏–º–µ–µ—Ç –º–µ—Ç–æ–¥ get()
            return requests.get(url)
        except (requests.RequestException, ValueError):
            return None

    def _parse_page(self, url: str, response: requests.Response) -> None:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        soup = BeautifulSoup(response.content, 'html.parser')
        row: Dict[str, Optional[str]] = {'URL': url}  # –Ø–≤–Ω–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ —Ç–∏–ø–∞
        
        for col_name, selector in self.selectors.items():
            element = soup.select_one(selector)
            row[col_name] = element.get_text(strip=True) if element else None
            
        self.data.append(row)

    def _add_empty_row(self, url: str) -> None:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏ —Å –ø—É—Å—Ç—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–∏ –æ—à–∏–±–∫–µ –∑–∞–≥—Ä—É–∑–∫–∏"""
        row: Dict[str, Optional[str]] = {'URL': url}
        row.update({col: None for col in self.selectors})
        self.data.append(row)

    def _build_dataframe(self) -> pd.DataFrame:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ DataFrame"""
        df = pd.DataFrame(self.data)
        return df.set_index('URL')
```

---
## `catalog_parser.py`
* **–û–ø–∏—Å–∞–Ω–∏–µ**: –ü–∞—Ä—Å–µ—Ä –∫–∞—Ç–∞–ª–æ–≥–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—Å—ã–ª–æ–∫ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü.
* **–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç**: –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å, –≥–¥–µ –∫–ª—é—á - –∑–∞–≥–æ–ª–æ–≤–æ–∫ H1 —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–∏–ª–∏ URL –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ H1), –∑–Ω–∞—á–µ–Ω–∏–µ - —Å–ø–∏—Å–æ–∫ –∞–±—Å–æ–ª—é—Ç–Ω—ã—Ö —Å—Å—ã–ª–æ–∫, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö CSS-—Å–µ–ª–µ–∫—Ç–æ—Ä—É.
* **–ê–∫—Ç—É–∞–ª—å–Ω—ã–π –∫–æ–¥ `catalog_parser.py`**:
```python
import requests
from bs4 import BeautifulSoup
from typing import Union, List, Dict, Optional
from urllib.parse import urljoin
from auth import CNC1Auth

class CatalogParser:
    """
    –ü–∞—Ä—Å–µ—Ä –∫–∞—Ç–∞–ª–æ–≥–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—Å—ã–ª–æ–∫ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å, –≥–¥–µ –∫–ª—é—á - –∑–∞–≥–æ–ª–æ–≤–æ–∫ H1 —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–∏–ª–∏ URL –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ H1),
    –∑–Ω–∞—á–µ–Ω–∏–µ - —Å–ø–∏—Å–æ–∫ –∞–±—Å–æ–ª—é—Ç–Ω—ã—Ö —Å—Å—ã–ª–æ–∫, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö CSS-—Å–µ–ª–µ–∫—Ç–æ—Ä—É.
    """
    
    def __init__(
        self,
        urls: Union[str, List[str]],
        link_selector: str,
        auth: Optional[CNC1Auth] = None
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞ –∫–∞—Ç–∞–ª–æ–≥–∞.
        
        :param urls: URL –∏–ª–∏ —Å–ø–∏—Å–æ–∫ URL –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        :param link_selector: CSS-—Å–µ–ª–µ–∫—Ç–æ—Ä –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—Å—ã–ª–æ–∫
        :param auth: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –æ–±—ä–µ–∫—Ç –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ (CNC1Auth)
        """
        self.urls = [urls] if isinstance(urls, str) else urls
        self.link_selector = link_selector
        self.auth = auth
        self.result: Dict[str, List[str]] = {}

    def parse(self) -> Dict[str, List[str]]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        for url in self.urls:
            response = self._fetch_page(url)
            if response is None or response.status_code != 200:
                self._add_empty_result(url)
                continue
                
            soup = BeautifulSoup(response.content, 'html.parser')
            key = self._get_page_key(soup, url)
            links = self._extract_links(soup, url)
            self.result[key] = links
            
        return self.result

    def _fetch_page(self, url: str) -> Optional[requests.Response]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        try:
            if self.auth and self.auth.is_authenticated():
                return self.auth.get(url)
            return requests.get(url, timeout=10)
        except requests.RequestException:
            return None

    def _get_page_key(self, soup: BeautifulSoup, url: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (H1 –∏–ª–∏ URL)"""
        h1_tag = soup.find('h1')
        return h1_tag.get_text(strip=True) if h1_tag else url

    def _extract_links(self, soup: BeautifulSoup, base_url: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Å—ã–ª–æ–∫"""
        links = []
        elements = soup.select(self.link_selector)
        
        for el in elements:
            href = el.get('href')
            if href is not None:
                # –Ø–≤–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ href –≤ —Å—Ç—Ä–æ–∫—É
                href_str = str(href).strip()
                if href_str:  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
                    absolute_url = urljoin(base_url, href_str)
                    links.append(absolute_url)
                
        return links

    def _add_empty_result(self, url: str) -> None:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü"""
        self.result[url] = []
```

---
## `config_reader.py`
* **–û–ø–∏—Å–∞–Ω–∏–µ**: –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–∞—Ä—Å–∏–Ω–≥ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏. –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç Dependency Injection.
* **–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç**: —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–æ–Ω—Ñ–∏–≥–∞ –¥–ª—è –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –∫–ª–∞—Å—Å–æ–≤.
* **–ê–∫—Ç—É–∞–ª—å–Ω—ã–π –∫–æ–¥ `config_reader.py`**:
```python
import json
import os
from typing import Dict, Any

class ConfigReader:
    def __init__(self, config_name: str = "config.json"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —á–∏—Ç–∞—Ç–µ–ª—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏.
        :param config_name: –ò–º—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é config.json)
        """
        self.config_path = os.path.join(os.getcwd(), config_name)
        self.config_data: Dict[str, Any] = {}
        self._load_config()

    def _load_config(self) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–∞—Ä—Å–∏–Ω–≥ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                self.config_data = json.load(f)
        except FileNotFoundError:
            raise FileNotFoundError(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.config_path}")
        except json.JSONDecodeError:
            raise ValueError(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –≤ —Ñ–∞–π–ª–µ: {self.config_path}")

    def get_auth_credentials(self) -> Dict[str, str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        auth_section = self.config_data.get("auth", {})
        return {
            "email": auth_section.get("email", ""),
            "password": auth_section.get("pass", "")  # –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –∫–ª—é—á "pass"
        }

    def get_link_selector(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ CSS-—Å–µ–ª–µ–∫—Ç–æ—Ä–∞ –¥–ª—è —Å—Å—ã–ª–æ–∫"""
        return self.config_data.get("settings", {}).get("link_selector", "")
    
    def get_selectors(self) -> Dict[str, str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è CSS-—Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤"""
        return self.config_data.get("settings", {}).get("selectors", {})
    
    def get_settings(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ–≥–æ —Ä–∞–∑–¥–µ–ª–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫"""
        return self.config_data.get("settings", {})
```

---
## `web_ui.py`
* **–û–ø–∏—Å–∞–Ω–∏–µ**: Streamlit –≤–µ–± –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø–∞—Ä—Å–µ—Ä–∞.
* **–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç**: –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ.
* **–ê–∫—Ç—É–∞–ª—å–Ω—ã–π –∫–æ–¥ `web_ui.py`**:
```python
import streamlit as st
import pandas as pd
import logging
from io import BytesIO
from typing import List, Dict, Any, Optional
from catalog_parser import CatalogParser
from page_parser import PageParser
from config_reader import ConfigReader
from auth import CNC1Auth

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–≥–≥–µ—Ä–∞
logger = logging.getLogger(__name__)

class StreamlitLogger:
    """–ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ª–æ–≥–æ–≤ –≤ Streamlit –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å"""
    def __init__(self):
        self.log_container = st.empty()
        self.logs: List[str] = []
        
    def log(self, message: str, level: str = "info"):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –ª–æ–≥"""
        log_entry = f"[{level.upper()}] {message}"
        self.logs.append(log_entry)
        
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 —Å–æ–æ–±—â–µ–Ω–∏–π
        display_log = "\n".join(self.logs[-20:])
        self.log_container.text_area("–ñ—É—Ä–Ω–∞–ª –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:", 
                                    value=display_log, 
                                    height=200,
                                    disabled=True)
        
    def clear(self):
        """–û—á–∏—Å—Ç–∫–∞ –ª–æ–≥–æ–≤"""
        self.logs = []
        self.log_container.empty()

class InputManager:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–≤–æ–¥–æ–º –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π URL"""
    @staticmethod
    def get_urls(link_type: str) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å–ø–∏—Å–∫–∞ URL"""
        url_input = st.text_area(
            "–í–≤–µ–¥–∏—Ç–µ URL (–∫–∞–∂–¥—ã–π —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏ –∏–ª–∏ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é):",
            height=150,
            placeholder="https://example.com/page1\nhttps://example.com/page2"
        )
        
        if not url_input:
            return []
            
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ URL –ø–æ –ø–µ—Ä–µ–Ω–æ—Å–∞–º –∏ –∑–∞–ø—è—Ç—ã–º
        urls = []
        for line in url_input.splitlines():
            if "," in line:
                urls.extend([u.strip() for u in line.split(",") if u.strip()])
            else:
                if line.strip():
                    urls.append(line.strip())
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è URL
        valid_urls = []
        for url in urls:
            if url.startswith(("http://", "https://")):
                # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä SHOWALL_1=1 –¥–ª—è –∫–∞—Ç–∞–ª–æ–≥–æ–≤
                if link_type == "–ö–∞—Ç–∞–ª–æ–≥":
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ URL
                    if '?' in url:
                        # –ï—Å–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —É–∂–µ –µ—Å—Ç—å, –¥–æ–±–∞–≤–ª—è–µ–º —Å &
                        if 'SHOWALL_1=1' not in url:
                            url += '&SHOWALL_1=1'
                    else:
                        # –ï—Å–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–µ—Ç, –¥–æ–±–∞–≤–ª—è–µ–º —Å ?
                        url += '?SHOWALL_1=1'
                valid_urls.append(url)
            else:
                st.warning(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL: {url} (–¥–æ–ª–∂–µ–Ω –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å http:// –∏–ª–∏ https://)")
        
        return valid_urls

class ResultDispatcher:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    @staticmethod
    def preview_data(df: pd.DataFrame):
        """–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—á–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ"""
        if not df.empty:
            st.subheader("–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö")
            st.dataframe(df.head(50))
            st.info(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}")
        else:
            st.warning("–î–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")

class ResultExporter:
    """–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã"""
    @staticmethod
    def to_csv(df: pd.DataFrame) -> bytes:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DataFrame –≤ CSV"""
        return df.to_csv(index=True).encode('utf-8')
    
    @staticmethod
    def to_excel(df: pd.DataFrame) -> bytes:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DataFrame –≤ Excel"""
        output = BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            df.to_excel(writer, sheet_name='Products')
        return output.getvalue()

class WebInterface:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
    def __init__(self):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Å—Å–∏–∏
        if 'df' not in st.session_state:
            st.session_state.df = pd.DataFrame()
        if 'parsing' not in st.session_state:
            st.session_state.parsing = False
        if 'stop_requested' not in st.session_state:
            st.session_state.stop_requested = False
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        self.config = ConfigReader()
        self.auth = self._init_auth()
        self.logger = StreamlitLogger()
        
    def _init_auth(self) -> Optional[CNC1Auth]:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        try:
            credentials = self.config.get_auth_credentials()
            if credentials['email'] and credentials['password']:
                auth = CNC1Auth(credentials['email'], credentials['password'])
                if auth.login():
                    return auth
                else:
                    st.error("–û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—á–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.")
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏: {str(e)}")
        return None

    def _parse_catalog(self, urls: List[str]) -> List[str]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∫–∞—Ç–∞–ª–æ–≥–∞ –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ç–æ–≤–∞—Ä—ã"""
        parser = CatalogParser(
            urls=urls,
            link_selector=self.config.get_link_selector(),
            auth=self.auth
        )
        
        catalog_result = parser.parse()
        product_urls = []
        
        for category, urls in catalog_result.items():
            self.logger.log(f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è '{category}': {len(urls)} —Ç–æ–≤–∞—Ä–æ–≤")
            product_urls.extend(urls)
        
        return product_urls

    def _parse_products(self, urls: List[str]) -> pd.DataFrame:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü —Ç–æ–≤–∞—Ä–æ–≤"""
        parser = PageParser(
            urls=urls,
            selectors=self.config.get_selectors(),
            auth=self.auth
        )
        
        return parser.parse()
    
    def _normalize_article(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∞—Ä—Ç–∏–∫—É–ª–∞: –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–µ—Ñ–∏–∫—Å–∞ 123-"""
        if not df.empty and "–ê—Ä—Ç–∏–∫—É–ª" in df.columns:
            # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
            normalized_df = df.copy()
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ –∫ –Ω–µ–ø—É—Å—Ç—ã–º –∑–Ω–∞—á–µ–Ω–∏—è–º
            normalized_df["–ê—Ä—Ç–∏–∫—É–ª"] = normalized_df["–ê—Ä—Ç–∏–∫—É–ª"].apply(
                lambda x: f"123-{x}" if x and not pd.isna(x) else x
            )
            return normalized_df
        return df

    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
        st.title("üõ†Ô∏è –ü–∞—Ä—Å–µ—Ä CNC1")
        st.markdown("---")
        
        # –ü–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—å —Ç–∏–ø–∞ —Å—Å—ã–ª–æ–∫
        link_type = st.radio(
            "–¢–∏–ø –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã—Ö —Å—Å—ã–ª–æ–∫:",
            ["–ö–∞—Ä—Ç–æ—á–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤", "–ö–∞—Ç–∞–ª–æ–≥"],
            index=0,
            horizontal=True
        )
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ URL
        input_urls = InputManager.get_urls(link_type)
        
        col1, col2 = st.columns(2)
        with col1:
            start_btn = st.button(
                "üöÄ –ù–∞—á–∞—Ç—å –ø–∞—Ä—Å–∏–Ω–≥", 
                disabled=st.session_state.parsing or not input_urls
            )
        with col2:
            stop_btn = st.button(
                "‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å", 
                disabled=not st.session_state.parsing
            )
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–Ω–æ–ø–æ–∫
        if start_btn and input_urls:
            st.session_state.parsing = True
            st.session_state.stop_requested = False
            self.logger.clear()
            
            try:
                # –í—ã–±–æ—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞
                if link_type == "–ö–∞—Ç–∞–ª–æ–≥":
                    self.logger.log("–ù–∞—á–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥ –∫–∞—Ç–∞–ª–æ–≥–∞...")
                    product_urls = self._parse_catalog(input_urls)
                    
                    if not product_urls:
                        st.error("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ç–æ–≤–∞—Ä—ã –≤ –∫–∞—Ç–∞–ª–æ–≥–µ")
                        st.session_state.parsing = False
                        return
                        
                    self.logger.log(f"–í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞: {len(product_urls)}")
                    st.session_state.df = self._parse_products(product_urls)
                else:
                    self.logger.log("–ù–∞—á–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥ –∫–∞—Ä—Ç–æ—á–µ–∫ —Ç–æ–≤–∞—Ä–æ–≤...")
                    st.session_state.df = self._parse_products(input_urls)
                
                self.logger.log("–ü–∞—Ä—Å–∏–Ω–≥ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!", "success")
                
            except Exception as e:
                self.logger.log(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}", "error")
                st.error("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –ø–∞—Ä—Å–∏–Ω–≥–∞")
                
            finally:
                st.session_state.parsing = False
        
        if stop_btn:
            st.session_state.stop_requested = True
            st.session_state.parsing = False
            self.logger.log("–ü–∞—Ä—Å–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º", "warning")
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–µ—Ä–µ–¥ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
        display_df = self._normalize_article(st.session_state.df)

        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        ResultDispatcher.preview_data(display_df)
        
        # –ö–Ω–æ–ø–∫–∏ —ç–∫—Å–ø–æ—Ä—Ç–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
        if not st.session_state.df.empty:
            st.markdown("### üì• –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            
            col1, col2 = st.columns(2)
            with col1:
                # –≠–∫—Å–ø–æ—Ä—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                normalized_df = self._normalize_article(st.session_state.df)
                csv_data = ResultExporter.to_csv(normalized_df)
                st.download_button(
                    "üíæ –°–∫–∞—á–∞—Ç—å CSV",
                    data=csv_data,
                    file_name='products.csv',
                    mime='text/csv',
                )
            
            with col2:
                # –≠–∫—Å–ø–æ—Ä—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                normalized_df = self._normalize_article(st.session_state.df)
                excel_data = ResultExporter.to_excel(normalized_df)
                st.download_button(
                    "üíæ –°–∫–∞—á–∞—Ç—å XLSX",
                    data=excel_data,
                    file_name='products.xlsx',
                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                )

if __name__ == "__main__":
    web_ui = WebInterface()
    web_ui.run()
```